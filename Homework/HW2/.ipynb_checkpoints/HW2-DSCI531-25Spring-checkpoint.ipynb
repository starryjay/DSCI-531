{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d33ac88",
   "metadata": {},
   "source": [
    "# HW2 - Bias in Data and Prediction - DSCI 531 - Spring 2025\n",
    "\n",
    "### Please complete the code or analysis under \"TODO\". 80pts in total. You should run every cell and keep all the outputs before submitting. Failing to include your outputs will result in zero points.\n",
    "### Please keep academic integrity in mind. Plagiarism will be taken seriously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c56c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c75bf7",
   "metadata": {},
   "source": [
    "## 1. Implement Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8b61d",
   "metadata": {},
   "source": [
    "### 1.1 Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5455541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are NOT allowed to use off-the-shelf fairness packages like ai360\n",
    "\n",
    "def stat_parity(preds, sens):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :return: the statistical parity. no need to take the absolute value\n",
    "    '''\n",
    "    \n",
    "    # TODO. 10pts\n",
    "    p_pos = np.mean(preds[sens == 1])\n",
    "    p_neg = np.mean(preds[sens == 0])\n",
    "    \n",
    "    return f'Statistical Parity: {p_pos - p_neg}'\n",
    "\n",
    "\n",
    "def eq_oppo(preds, sens, labels):\n",
    "    '''\n",
    "    :preds: numpy array of the model predictions. Consisting of 0s and 1s\n",
    "    :sens: numpy array of the sensitive features. Consisting of 0s and 1s\n",
    "    :labels: numpy array of the ground truth labels of the outcome. Consisting of 0s and 1s\n",
    "    :return: the equal opportunity difference. no need to take the absolute value\n",
    "    '''\n",
    "    # TODO. 10pts\n",
    "    tpr_pos = np.mean(preds[(sens == 1) & (labels == 1)]) if np.any(((sens == 1) & (labels == 1))) else 0\n",
    "    tpr_neg = np.mean(preds[(sens == 0) & (labels == 1)]) if np.any(((sens == 0) & (labels == 1))) else 0\n",
    "    return f'Equal Opportunity Difference: {tpr_pos - tpr_neg}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "02d3a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal Opportunity Difference: 0.4\n",
      " Statistical Parity: -0.125\n",
      "Equal Opportunity Difference: -0.75\n",
      " Statistical Parity: 0.5\n",
      "Equal Opportunity Difference: 0.0\n",
      " Statistical Parity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented fairness metrics using the code below\n",
    "# Don't change the code in this cell\n",
    "\n",
    "# test case 1\n",
    "preds = np.array([1, 0, 1, 0, 0, 1, 0, 0, 0, 1])\n",
    "sens = np.array([1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "# test case 2\n",
    "preds = np.array([1, 1, 0, 1, 0, 1, 0, 0, 1, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))\n",
    "\n",
    "\n",
    "# test case 3\n",
    "preds = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "sens = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "labels = np.array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
    "print(eq_oppo(preds, sens, labels), stat_parity(preds, sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c1b21",
   "metadata": {},
   "source": [
    "### 1.2 Preprocessing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a3aef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs(df_train_x, df_test_x, categ_cols):\n",
    "    '''\n",
    "    Pre-process the features of the training set and the test set, not including the outcome column.\n",
    "    Convert categorical features (nominal & ordinal features) to one-hot encodings.\n",
    "    Normalize the numerical features into [0, 1].\n",
    "    We process training set and the test set together in order to make sure that \n",
    "    the encodings are consistent between them.\n",
    "    For example, if one class is encoded as 001 and another class is encoded as 010 in the training set,\n",
    "    you should follow this mapping for the test set too.\n",
    "    \n",
    "    :df_train: the dataframe of the training data\n",
    "    :df_test: the dataframe of the test data\n",
    "    :categ_cols: the column names of the categorical features. the rest features are treated as numerical ones.\n",
    "    :return: the processed training data and test data, both should be numpy arrays, instead of DataFrames\n",
    "    '''\n",
    "        \n",
    "    # TODO. 10pts\n",
    "    \n",
    "    all_data = pd.concat([df_train_x, df_test_x], axis=0) \n",
    "    all_data = pd.get_dummies(all_data, columns=categ_cols)\n",
    "    \n",
    "    train_x = all_data.iloc[:len(df_train_x), :].copy()\n",
    "    test_x = all_data.iloc[len(df_train_x):, :].copy()\n",
    "\n",
    "    num_cols = df_train_x.columns.difference(categ_cols)\n",
    "\n",
    "    for column in num_cols:\n",
    "        mn = train_x[column].min()\n",
    "        mx = train_x[column].max()\n",
    "        mmrange = mx - mn\n",
    "        \n",
    "        if mmrange > 0:\n",
    "            train_x[column] = (train_x[column] - mn) / mmrange\n",
    "            test_x[column] = (test_x[column] - mn) / mmrange\n",
    "            \n",
    "\n",
    "    return train_x.to_numpy(), test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "54b0b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7142857142857143 True False False True False False]\n",
      " [1.0 True False False False True False]\n",
      " [0.0 False True False True False False]\n",
      " [0.2857142857142857 False False True False False True]]\n",
      "\n",
      "[[1.5714285714285714 True False False False True False]\n",
      " [0.5714285714285714 False False True True False False]]\n"
     ]
    }
   ],
   "source": [
    "# Test your implemented data preprocessing function\n",
    "# DO NOT change the code in this cell\n",
    "\n",
    "df_train_x = pd.DataFrame([\n",
    "    [ 'big', 10, 'blue',],\n",
    "    [ 'big', 12, 'red',],\n",
    "    ['medium', 5, 'blue'],\n",
    "    ['small', 7, 'yellow']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "df_test_x = pd.DataFrame([\n",
    "    [ 'big', 16, 'red',],\n",
    "    ['small', 9, 'blue']\n",
    "], columns=['size', 'height', 'color'])\n",
    "\n",
    "train_data_x, test_data_x = process_dfs(df_train_x, df_test_x, categ_cols=['size', 'color'])\n",
    "print(train_data_x)\n",
    "print()\n",
    "print(test_data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc8867",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "34361f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adult = pd.read_csv('adult-train.csv', sep=', ', engine='python')\n",
    "df_test_adult = pd.read_csv('adult-test.csv', sep=', ', engine='python')\n",
    "df_train_adult['sex'] = df_train_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_test_adult['sex'] = df_test_adult['sex'].map({'Male': 0, 'Female': 1})\n",
    "df_train_adult['income'] = df_train_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "df_test_adult['income'] = df_test_adult['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "\n",
    "df_train_german = pd.read_csv('german-train.csv')\n",
    "df_test_german = pd.read_csv('german-test.csv')\n",
    "df_train_german['age'] = df_train_german['age'].apply(lambda x: 1 if x >= 33 else 0)\n",
    "df_test_german['age'] = df_test_german['age'].apply(lambda x: 1 if x>=33 else 0)\n",
    "df_train_german['credit_status'] = df_train_german['credit_status'].map({2:0, 1:1})\n",
    "df_test_german['credit_status'] = df_test_german['credit_status'].map({2:0, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "498e89dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    0   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    0   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    0   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    0   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black    1   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
       "0          2174             0              40  United-States       0  \n",
       "1             0             0              13  United-States       0  \n",
       "2             0             0              40  United-States       0  \n",
       "3             0             0              40  United-States       0  \n",
       "4             0             0              40           Cuba       0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e950c415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_account</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_account</th>\n",
       "      <th>present_employment_since</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>credit_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A14</td>\n",
       "      <td>21</td>\n",
       "      <td>A32</td>\n",
       "      <td>A41</td>\n",
       "      <td>5248</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>1987</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A121</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A151</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>5742</td>\n",
       "      <td>A62</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A14</td>\n",
       "      <td>36</td>\n",
       "      <td>A32</td>\n",
       "      <td>A49</td>\n",
       "      <td>7409</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>1</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A42</td>\n",
       "      <td>1221</td>\n",
       "      <td>A65</td>\n",
       "      <td>A73</td>\n",
       "      <td>1</td>\n",
       "      <td>A94</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_account  duration credit_history purpose  credit_amount  \\\n",
       "0              A14        21            A32     A41           5248   \n",
       "1              A11        24            A32     A43           1987   \n",
       "2              A14        36            A32     A49           5742   \n",
       "3              A14        36            A32     A49           7409   \n",
       "4              A14         6            A34     A42           1221   \n",
       "\n",
       "  savings_account present_employment_since  installment_rate  \\\n",
       "0             A65                      A73                 1   \n",
       "1             A61                      A73                 2   \n",
       "2             A62                      A74                 2   \n",
       "3             A65                      A75                 3   \n",
       "4             A65                      A73                 1   \n",
       "\n",
       "  personal_status_sex other_debtors  ...  property age  \\\n",
       "0                 A93          A101  ...      A123   0   \n",
       "1                 A93          A101  ...      A121   0   \n",
       "2                 A93          A101  ...      A123   0   \n",
       "3                 A93          A101  ...      A122   1   \n",
       "4                 A94          A101  ...      A122   0   \n",
       "\n",
       "   other_installment_plans housing num_credits   job num_people_liable  \\\n",
       "0                     A143    A152           1  A173                 1   \n",
       "1                     A143    A151           1  A172                 2   \n",
       "2                     A143    A152           2  A173                 1   \n",
       "3                     A143    A152           2  A173                 1   \n",
       "4                     A143    A152           2  A173                 1   \n",
       "\n",
       "   telephone foreign_worker credit_status  \n",
       "0       A191           A201             1  \n",
       "1       A191           A201             0  \n",
       "2       A192           A201             1  \n",
       "3       A191           A201             1  \n",
       "4       A191           A201             1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_german.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c297f2",
   "metadata": {},
   "source": [
    "## 3. Explore fairness in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78093a00",
   "metadata": {},
   "source": [
    "### 3.1 statistical analysis on protected feature and outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0747aee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3138370951913641 0.11367818442036394\n",
      "0.6636363636363637 0.7594594594594595\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# calculate the mean income of two protected groups. only use the training data df_train_adult. \n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_income1_adult = df_train_adult.loc[lambda x: x['sex'] == 0]['income'].mean()\n",
    "mean_income2_adult = df_train_adult.loc[lambda x: x['sex'] == 1]['income'].mean()\n",
    "\n",
    "print(mean_income1_adult, mean_income2_adult)\n",
    "\n",
    "\n",
    "# German\n",
    "# calculate the mean credit status of two protected groups. only use the training data df_train_german. \n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "mean_credit1_german = df_train_german.loc[lambda x: x['age'] == 0]['credit_status'].mean()\n",
    "mean_credit2_german = df_train_german.loc[lambda x: x['age'] == 1]['credit_status'].mean()\n",
    "\n",
    "print(mean_credit1_german, mean_credit2_german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9836be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.005042713073567462\n"
     ]
    }
   ],
   "source": [
    "# t-test between outcome of two protected groups. only use the training data df_train_adult/german.\n",
    "from scipy import stats\n",
    "\n",
    "# Adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "m_income = df_train_adult.loc[lambda x: x['sex'] == 0]['income']\n",
    "f_income = df_train_adult.loc[lambda x: x['sex'] == 1]['income']\n",
    "t_stat_adult, p_value_adult = stats.ttest_ind(m_income, f_income)\n",
    "\n",
    "# german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "below_33 = df_train_german.loc[lambda x: x['age'] == 0]['credit_status']\n",
    "above_33 = df_train_german.loc[lambda x: x['age'] == 1]['credit_status']\n",
    "t_stat_german, p_value_german = stats.ttest_ind(below_33, above_33)\n",
    "\n",
    "\n",
    "print(p_value_adult, p_value_german)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71338e78",
   "metadata": {},
   "source": [
    "### From the p_values, are the results significant for Adult and German? How do you explain them?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 3pts\n",
    "\n",
    "If we fix the significance threshold $\\alpha$ at 0.05, then both results are statistically significant - it appears that sex has a significant influence on income class, and age has a significant influence on credit status. The former can be explained by gendered pay gaps as well as the exclusion of women from high-paying careers, while the latter can be explained by the fact that a large factor in credit score is the number of years for which one has been able to maintain a line of credit, and of course with advanced age "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee79391",
   "metadata": {},
   "source": [
    "### 3.2 Explore Fairness in Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e7c9c36-2a46-4d3c-b301-27f3593e354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 103) (15060, 102) (30162,) (15060,)\n",
      "(700, 61) (300, 61) (700,) (300,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "# Dont't change code in this cell\n",
    "\n",
    "'''\n",
    ":train_x: the features in the training set (including the sensitive features), shape: N_train x d\n",
    ":train_y: the outcome in the training set, shape: N_train\n",
    ":test_x: the features in the test set (including the sensitive features), shape: N_test x d\n",
    ":test_y: the outcome in the test set, shape: N_test\n",
    ":test_sens: the sensitive/protected feature in the test set, shape: N_test\n",
    "All of them are processed numpy arrays that are ready for algorithms.\n",
    "'''\n",
    "\n",
    "\n",
    "# adult\n",
    "# the outcome (income) is the last column\n",
    "df_train_x_adult = df_train_adult.iloc[:, :-1]\n",
    "df_train_y_adult = df_train_adult.iloc[:, -1]\n",
    "df_test_x_adult = df_test_adult.iloc[:, :-1]\n",
    "df_test_y_adult = df_test_adult.iloc[:, -1]\n",
    "df_test_sens_adult = df_test_adult['sex']\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_adult.values\n",
    "test_y_adult = df_test_y_adult.values\n",
    "test_sens_adult = df_test_sens_adult.values\n",
    "\n",
    "# german\n",
    "# the outcome (credit status) is the last column\n",
    "df_train_x_german = df_train_german.iloc[:, :-1]\n",
    "df_train_y_german = df_train_german.iloc[:, -1]\n",
    "df_test_x_german = df_test_german.iloc[:, :-1]\n",
    "df_test_y_german = df_test_german.iloc[:, -1]\n",
    "df_test_sens_german = df_test_german['age']\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "train_y_german = df_train_y_german.values\n",
    "test_y_german = df_test_y_german.values\n",
    "test_sens_german = df_test_sens_german.values\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape, train_y_adult.shape, test_y_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape, train_y_german.shape, test_y_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4060f120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- native-country_Holand-Netherlands\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m lr_adult\u001b[38;5;241m.\u001b[39mfit(train_x_adult, train_y_adult)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# predict the outcome from test_x_adult\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO. 3pts. The starter code below just indicate what you need to output in your code.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m preds \u001b[38;5;241m=\u001b[39m lr_adult\u001b[38;5;241m.\u001b[39mpredict(test_x_adult)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# report acc and two fairness metrics. \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "File \u001b[0;32m~/anaconda3/envs/baseenv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m~/anaconda3/envs/baseenv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/envs/baseenv/lib/python3.11/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/baseenv/lib/python3.11/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- native-country_Holand-Netherlands\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "\n",
    "lr_adult = LogisticRegression()\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 4pts\n",
    "\n",
    "lr_adult.fit(train_x_adult, train_y_adult)\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = lr_adult.predict(test_x_adult)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics. \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 3pts\n",
    "\n",
    "lr_german = LogisticRegression()\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 4pts\n",
    "lr_german.fit(train_x_german, train_y_german)\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "preds = lr_german.predict(test_x_german)\n",
    "\n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8e5d4",
   "metadata": {},
   "source": [
    "## 4. Explore possible ways to mitigate bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b955793",
   "metadata": {},
   "source": [
    "### 4. 1 remove protected attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7f484b96",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2915075797.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[129], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_train_x_no_sens_adult =\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# remove the sex column from df_train_x_adult and df_test_x_adult. \n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_test_x_adult\n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_adult = \n",
    "df_test_x_no_sens_adult = \n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_no_sens_adult, df_test_x_no_sens_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "\n",
    "\n",
    "# German\n",
    "# remove age column from df_train_x_german and df_test_x_german\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_test_x_german\n",
    "# TODO. 2pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_no_sens_german = \n",
    "df_test_x_no_sens_german = \n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_no_sens_german, df_test_x_no_sens_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "\n",
    "\n",
    "print(train_x_adult.shape, test_x_adult.shape)\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4145617a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3118370927.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[130], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    preds =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x (with protected feature removed)\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = \n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = \n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0face94",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does explicitly removing the sensitive feature help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 5pts\n",
    "xxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2279414",
   "metadata": {},
   "source": [
    "### 4.2 Augmenting the training set\n",
    "\n",
    "#### See the example in Figure 1 of https://dl.acm.org/doi/pdf/10.1145/3375627.3375865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "71a69738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3785629837.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[131], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    df_train_x_syn_adult =\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "# create a synthetic training set by duplicating df_train_x_adult and df_train_y_adult\n",
    "# after duplicating flip sex in the synthetic set\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_adult or df_train_y_adult\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_adult = \n",
    "df_train_y_syn_adult = \n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_adult = pd.concat((df_train_x_adult, df_train_x_syn_adult))\n",
    "df_train_y_aug_adult = pd.concat((df_train_y_adult, df_train_y_syn_adult))\n",
    "\n",
    "print(df_train_x_aug_adult.shape, df_train_y_aug_adult.shape)\n",
    "\n",
    "\n",
    "train_x_adult, test_x_adult = process_dfs(df_train_x_aug_adult, df_test_x_adult, \n",
    "                                                   ['workclass', 'education','marital-status',\n",
    "                                                    'occupation','relationship','race',\n",
    "                                                    'native-country'])\n",
    "train_y_adult = df_train_y_aug_adult.values\n",
    "print(train_x_adult.shape, test_x_adult.shape, train_y_adult.shape)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "# create a synthetic training set by duplicating df_train_x_german and df_train_y_german\n",
    "# after duplicating flip age in the synthetic set.\n",
    "# You shouldn't do it in-place. In other words, do not modify df_train_x_german or df_train_y_german\n",
    "# TODO. 3pts. The starter code below just indicate what you need to output in your code.\n",
    "df_train_x_syn_german = \n",
    "df_train_y_syn_german = \n",
    "\n",
    "\n",
    "# augment the original training set by the synthetic set. In other words, concatenate them\n",
    "df_train_x_aug_german = pd.concat((df_train_x_german, df_train_x_syn_german))\n",
    "df_train_y_aug_german = pd.concat((df_train_y_german, df_train_y_syn_german))\n",
    "\n",
    "train_y_german = df_train_y_aug_german.values\n",
    "\n",
    "print(df_train_x_aug_german.shape, df_train_y_aug_german.shape, train_y_german.shape)\n",
    "\n",
    "\n",
    "train_x_german, test_x_german = process_dfs(df_train_x_aug_german, df_test_x_german,\n",
    "                                                     ['checking_account', 'credit_history', \n",
    "                                                      'purpose', 'savings_account', 'present_employment_since', \n",
    "                                                      'personal_status_sex', 'other_debtors',\n",
    "                                                     'property', 'other_installment_plans',\n",
    "                                                     'housing', 'job', 'telephone', 'foreign_worker'])\n",
    "print(train_x_german.shape, test_x_german.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e1791c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1084771365.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[132], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    preds =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# train a classifier to predict the outcome y from features x on the augmented training data\n",
    "# training: train_x --> train_y; test: test_x --> preds\n",
    "# logistic regression model is recommended\n",
    "# sklearn is allowed to use\n",
    "# Just use the code in 3.2 again\n",
    "\n",
    "\n",
    "# Adult\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_adult and train_y_adult\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_adult\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = \n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_adult, preds)\n",
    "stat_p = stat_parity(preds, test_sens_adult)\n",
    "eq_op = eq_oppo(preds, test_sens_adult, test_y_adult)\n",
    "print(acc, stat_p, eq_op)\n",
    "\n",
    "\n",
    "\n",
    "# German\n",
    "\n",
    "# initialize the model\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# train/fit the model with train_x_german and train_y_german\n",
    "# TODO. 0pt\n",
    "\n",
    "\n",
    "# predict the outcome from test_x_german\n",
    "# TODO. 0pt. The starter code below just indicate what you need to output in your code.\n",
    "preds = \n",
    "\n",
    "# report acc and two fairness metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(test_y_german, preds)\n",
    "stat_p = stat_parity(preds, test_sens_german)\n",
    "eq_op = eq_oppo(preds, test_sens_german, test_y_german)\n",
    "print(acc, stat_p, eq_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcf17e",
   "metadata": {},
   "source": [
    "### According to the results, how are the accuracy, stat parity and eq oppo different from the original model? Does augmenting the dataset with synthetic data help in mitigating bias? Why or why not?\n",
    "### <span style=\"color:red\">Please type your response here.</span> 5pts\n",
    "xxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a0daa-c917-4303-a266-8399e64a751d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec8f15-588e-4060-b7b5-811f4fdf7339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d5630-c369-403b-9ea1-11c614fac6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
